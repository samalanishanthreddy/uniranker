{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aebc423",
   "metadata": {},
   "source": [
    "# HACK YOUR PATH 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8547445",
   "metadata": {},
   "source": [
    "# UniRanker- A Holistic Information Retreival and Ranking Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836df53",
   "metadata": {},
   "source": [
    "## Step 1: Installing and Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fef1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d9de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03f49f",
   "metadata": {},
   "source": [
    "## Step 2: Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90706292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              qid  \\\n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "131      . what is a corporation?   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "226969  symptoms of a dying mouse   \n",
      "\n",
      "                                                    query  passage  label  \n",
      "131     A company is incorporated in a specific nation...        0      0  \n",
      "131     Today, there is a growing community of more th...        0      1  \n",
      "131     Corporation definition, an association of indi...        0      2  \n",
      "131     Examples of corporation in a Sentence. 1  He w...        0      3  \n",
      "131     1: a government-owned corporation (as a utilit...        0      4  \n",
      "131     McDonald's Corporation is one of the most reco...        1      5  \n",
      "131     Corporations are owned by their stockholders (...        0      6  \n",
      "131     An Association is an organized group of people...        0      7  \n",
      "131     B Corp certification shines a light on the com...        0      8  \n",
      "131     LLCs offer greater flexibility when it comes t...        0      9  \n",
      "226969  This can be fatal quite quickly to mice. 1  It...        0      0  \n",
      "226969  The symptoms of mites include: 1  excessive sc...        0      1  \n",
      "226969  Symptoms of Dog and Cat Poisoning. The symptom...        0      2  \n",
      "226969  The symptoms of mites include: excessive scrat...        0      3  \n",
      "226969  Seizures and neurologic symptoms are caused by...        0      4  \n",
      "226969  The symptoms are similar but the mouse will be...        1      5  \n",
      "226969  The symptoms are similar but the mouse will be...        0      6  \n",
      "226969  Depending on the poison ingested, a poisoned d...        0      7  \n",
      "226969  Some plants also cause neurologic symptoms, in...        0      8  \n",
      "226969  She described symptoms caused by permethrin: d...        0      9  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'sample.tsv'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter='\\t', header=None, names=['qid', 'query', 'passage', 'label'])\n",
    "\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b75ab",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing and Splitting the Dataset into Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e47af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "                                                qid  \\\n",
      "104220            how far is faribault from winona?   \n",
      "35300        can you burn your lawn with fertilizer   \n",
      "18122   average number of lightning strikes per day   \n",
      "20991             average temperature cardiff wales   \n",
      "20991             average temperature cardiff wales   \n",
      "\n",
      "                                                 question  passage  label  \n",
      "104220  Distance Between Faribault, MN and Winona, MN....        0      3  \n",
      "35300   Fertilizer burn is the result of over fertiliz...        1      8  \n",
      "18122   Lightning is a sudden high-voltage discharge o...        0      4  \n",
      "20991   Today. A rather cloudy start to the day; perha...        0      2  \n",
      "20991   The BBC is not responsible for the content of ...        0      1  \n",
      "\n",
      "Testing set:\n",
      "                                                      qid  \\\n",
      "57679                                   define preventive   \n",
      "226969                          symptoms of a dying mouse   \n",
      "140245              how much are postage stamps right now   \n",
      "80363   does xpress bet charge to deposit money in you...   \n",
      "139430  how many years did william bradford serve as g...   \n",
      "\n",
      "                                                 question  passage  label  \n",
      "57679   DEFINITION of 'Preventive Services'. Routine h...        0      2  \n",
      "226969  The symptoms are similar but the mouse will be...        1      5  \n",
      "140245  Find out the current price of a first class Un...        0      1  \n",
      "80363   Deposit checks 24/7. Take a photo of your chec...        0      7  \n",
      "139430  Home > Timelines > William Bradford Timeline W...        0      6  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'sample.tsv'\n",
    "df = pd.read_csv(file_path, delimiter='\\t', header=None, names=['qid', 'question', 'passage', 'label'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b0e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c162aef",
   "metadata": {},
   "source": [
    "## Step:4 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3337d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2054, 2003, 1037, 3840, 1029,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_and_pad_sequences(texts, max_length=128):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True,  \n",
    "    )\n",
    "\n",
    "    return tokens\n",
    "\n",
    "text = \"What is a corporation?\"\n",
    "tokens = tokenize_and_pad_sequences([text])\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a20d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"What is a corporation?\"\n",
    "tokens = tokenizer(\n",
    "    text,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True,\n",
    ")\n",
    "1\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4edde42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\anaconda\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea699bb9",
   "metadata": {},
   "source": [
    "## Step:5 BERT Model Preparing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ced71eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "max_sequence_length = 128  \n",
    "\n",
    "\n",
    "your_text_data = [\"Example text 1\", \"Example text 2\", \"Example text 3\"]\n",
    "\n",
    "\n",
    "tokenized_input = tokenizer(\n",
    "    your_text_data,\n",
    "    max_length=max_sequence_length,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "\n",
    "bert_output = bert_model(tokenized_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6240b78",
   "metadata": {},
   "source": [
    "## Step:6 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f065b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "file_path = \"sample.tsv\"  \n",
    "df = pd.read_csv(file_path, sep='\\t', header=None, names=['id', 'question', 'passage', 'label', 'some_column'])\n",
    "\n",
    "\n",
    "max_sequence_length = 128 \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_and_pad(text):\n",
    "    tokenized_input = tokenizer(\n",
    "        text,\n",
    "        max_length=max_sequence_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return tokenized_input\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = train_df.apply(lambda row: tokenize_and_pad(row['question'] + row['passage']), axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "\n",
    "X_test = test_df.apply(lambda row: tokenize_and_pad(row['question'] + row['passage']), axis=1)\n",
    "y_test = test_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b50ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "20/20 [==============================] - 218s 6s/step - loss: 0.3878 - accuracy: 0.8491\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 127s 6s/step - loss: 0.3504 - accuracy: 0.8868\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 126s 6s/step - loss: 0.3344 - accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d2807f2cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Building and Training the BERT Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "bert_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "bert_model.fit(\n",
    "    tf.concat([X_train[i]['input_ids'] for i in X_train.index], axis=0),\n",
    "    y_train.values,\n",
    "    epochs=3,  \n",
    "    batch_size=8  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f659a",
   "metadata": {},
   "source": [
    "## Step: 7 Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b07d4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 22s 2s/step - loss: 0.2218 - accuracy: 0.9500\n",
      "Test Accuracy: 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "evaluation = bert_model.evaluate(\n",
    "    tf.concat([X_test[i]['input_ids'] for i in X_test.index], axis=0),\n",
    "    y_test.values\n",
    ")\n",
    "\n",
    "print(\"Test Accuracy:\", evaluation[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de265a",
   "metadata": {},
   "source": [
    "## Step:8 Deploying the Passage Ranker Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d7b33a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc1f41ed07b4e159de115a614aa0a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Query:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf1f659cf9d4e0cbd2ab8f80f6d4884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Passage 1:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b010dc341d3a4419ab9417791163ebc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Passage 2:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059545579c6b491d9efd8d6da052f2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Passage 3:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ccc03223394a0b8c4c28985550cbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Passage 4:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e01536063436984e86759481a2b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Passage 5:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c820386069b458d8d0878cf1b12fa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: In our pursuit of knowledge and understanding, exploring outer space allows us to gain insights into the origins of our solar system and the universe, contributing to the advancement of human understanding and scientific progress.\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def make_prediction(query, passages):\n",
    "    \n",
    "    tokenized_inputs = [tokenizer(query + passage, return_tensors='tf', max_length=max_sequence_length, padding='max_length', truncation=True) for passage in passages]\n",
    "    \n",
    "    \n",
    "    model_inputs = {\n",
    "        'input_ids': tf.concat([tokenized_input['input_ids'] for tokenized_input in tokenized_inputs], axis=0),\n",
    "        'attention_mask': tf.concat([tokenized_input['attention_mask'] for tokenized_input in tokenized_inputs], axis=0),\n",
    "    }\n",
    "\n",
    "    \n",
    "    logits = bert_model(model_inputs, training=False).logits\n",
    "\n",
    "    \n",
    "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    \n",
    "    most_relevant_passage = passages[predicted_class]\n",
    "\n",
    "    return most_relevant_passage\n",
    "\n",
    "\n",
    "\n",
    "query_input = widgets.Text(description=\"Query:\")\n",
    "passage_inputs = [widgets.Text(description=f\"Passage {i+1}:\") for i in range(5)]\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "\n",
    "display(query_input)\n",
    "for passage_input in passage_inputs:\n",
    "    display(passage_input)\n",
    "display(submit_button)\n",
    "\n",
    "\n",
    "def on_submit_button_click(b):\n",
    "    query = query_input.value\n",
    "    passages = [passage_input.value for passage_input in passage_inputs]\n",
    "\n",
    "    \n",
    "    prediction = make_prediction(query, passages)\n",
    "\n",
    "    \n",
    "    print(f\"Predicted class: {prediction}\")\n",
    "     \n",
    "\n",
    "\n",
    "submit_button.on_click(on_submit_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca75927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
